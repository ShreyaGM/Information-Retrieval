import java.io.File;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
 
import org.apache.commons.lang.StringUtils;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.core.KeywordAnalyzer;
import org.apache.lucene.analysis.core.SimpleAnalyzer;
import org.apache.lucene.analysis.core.StopAnalyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.StringField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.MultiFields;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.Terms;
import org.apache.lucene.index.TermsEnum;
import org.apache.lucene.index.IndexWriterConfig.OpenMode;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.BytesRef;
import org.apache.lucene.util.Version;
 
 
public class generateIndex {
     
    public static void main(String[] args) throws IOException
    {
         
        Directory dir = FSDirectory.open(new File("C:\\Users\\Shreya\\Desktop\\Index"));
        Analyzer analyzer = new StandardAnalyzer();
        IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_4_10_0, analyzer);
        iwc.setOpenMode(OpenMode.CREATE);
        IndexWriter writer = new IndexWriter(dir, iwc);
         
        //specify corpus path
        File corpus = new File("C:\\Users\\Shreya\\Desktop\\corpus");
         
        for(File temp: corpus.listFiles())
        {
             
            //discard .DS_Store file
            if(!(temp.getName()).contains(".DS_Store"))
            {
            //getting path of every file in corpus
            Path path = Paths.get("C:\\Users\\Shreya\\Desktop\\corpus\\"+temp.getName());
            //converting file to string
            String filetostring = new String(Files.readAllBytes(path));
              
            //storing content between <DOC> tags in array
            String[] docs = StringUtils.substringsBetween(filetostring, "<DOC>","</DOC>");
              
            //iterate through the array to get content of other tags
            for ( String betweentags : docs)
            {
                Document luceneDoc = new Document();
                String[] docno=StringUtils.substringsBetween(betweentags, "<DOCNO>", "</DOCNO>");
                String[] text=StringUtils.substringsBetween(betweentags, "<TEXT>", "</TEXT>");
                String[] Byline=StringUtils.substringsBetween(betweentags, "<BYLINE>", "</BYLINE>");
                String[] dateline=StringUtils.substringsBetween(betweentags, "<DATELINE>", "</DATELINE>");
                String[] head=StringUtils.substringsBetween(betweentags, "<HEAD>", "</HEAD>");
                 
                 
                //to check for multiple occurrences of same tag and merge them
                String newdateline=null;
                if(dateline != null)
                {
                    for(int i=0;i<dateline.length;i++)
                    {
                        newdateline +=dateline[i];
                    }
                }
                String newdocno = "";
                if(docno != null)
                {
                    for(int i=0; i<docno.length;i++)
                    {
                        newdocno+=docno[i];
                    }
                }
                String newByline="";
                if(Byline!= null)
                {
                    for( int i=0; i<Byline.length; i++)
                    {
                        newByline+= Byline[i];
                    }
                }
                String newText = "";
                 if(text != null)
                 {
                      
                     for( int i=0; i<text.length; i++)
                     {
                         newText+= text[i];
                     }
                 }
                String newhead = "";
                 if(head != null)
                 {
                     for( int i=0; i<head.length; i++)
                     {
                         newhead+= head[i];
                     }
                }
                  
                 if(docno != null){
                 luceneDoc.add(new StringField("DOCNO",newdocno, Field.Store.YES));}
                 if(newText != null){
                 luceneDoc.add(new TextField("TEXT", newText, Field.Store.YES));}
                 if(newByline != null){
                 luceneDoc.add(new TextField("BYLINE", newByline, Field.Store.YES));}
                 if(newhead != null){
                 luceneDoc.add(new TextField("HEAD", newhead, Field.Store.YES));}
                 if(newdateline != null){
                 luceneDoc.add(new TextField("DATELINE", newdateline, Field.Store.YES));}
                 writer.addDocument(luceneDoc);
              
             }
         }
         }
         writer.forceMerge(1);
         writer.commit();
         writer.close();
         //printing statistics 
         IndexReader reader = DirectoryReader.open(FSDirectory.open(new File("C:\\Users\\Shreya\\Desktop\\Index")));
         System.out.println("Total number of documents in the corpus:"+reader.maxDoc());
         System.out.println("Number of documents containing the term \"new\" for field \"TEXT\": "+reader.docFreq(new Term("TEXT", "new")));
         System.out.println("Number of occurences of \"new\" in the field \"TEXT\": "+reader.totalTermFreq(new Term("TEXT","new")));
         Terms vocabulary = MultiFields.getTerms(reader, "TEXT");
         System.out.println("Size of the vocabulary for this field:"+vocabulary.size());
         System.out.println("Number of documents that have at least one term for this field: "+vocabulary.getDocCount());
         System.out.println("Number of tokens for this field:"+vocabulary.getSumTotalTermFreq());
         System.out.println("Number of postings for this field:"+vocabulary.getSumDocFreq());
         TermsEnum iterator = vocabulary.iterator(null);
         BytesRef byteRef = null;
         System.out.println("\n*******Vocabulary-Start**********");
         while((byteRef = iterator.next()) != null) 
         {
                String term = byteRef.utf8ToString();
                System.out.print(term+"\t");
         }
         System.out.println("\n*******Vocabulary-End**********");
         reader.close();    
             
    }
}
 
    
